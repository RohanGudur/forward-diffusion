# -*- coding: utf-8 -*-
"""forward diffusion images.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mQk-LG8tA-l9eb3g6OT_dauXxbdTbPEZ
"""

import torch
import torchvision
from torch import nn
from torch.utils.data import DataLoader
from torchvision import transforms
import matplotlib.pyplot as plt
import torch.nn.functional as F
import os

# Device configuration
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# Beta scheduler for the forward process
def linear_beta_schedule(timesteps, start=0.0001, end=0.02):
    return torch.linspace(start, end, timesteps)

T = 600
betas = linear_beta_schedule(timesteps=T)

# Pre-calculate different terms for closed form
alphas = 1. - betas
alphas_cumprod = torch.cumprod(alphas, axis=0)
alphas_cumprod_prev = F.pad(alphas_cumprod[:-1], (1, 0), value=1.0)
sqrt_recip_alphas = torch.sqrt(1.0 / alphas)
sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)
sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)
posterior_variance = betas * (1. - alphas_cumprod_prev) / (1. - alphas_cumprod)

# Define the index retrieval function
def get_index_from_list(vals, t, x_shape):
    """
    Returns a specific index t of a passed list of values vals
    while considering the batch dimension.
    """
    if t.item() >= len(vals):  # Check for index out of bounds
        raise IndexError(f"Index {t.item()} out of bounds for dimension {len(vals)}")
    out = vals[t]
    return out.view(t.shape[0], *([1] * (len(x_shape) - 1))).to(t.device)

def forward_diffusion_sample(x_0, t):
    noise = torch.randn_like(x_0)
    sqrt_alphas_cumprod_t = get_index_from_list(sqrt_alphas_cumprod, t, x_0.shape)
    sqrt_one_minus_alphas_cumprod_t = get_index_from_list(sqrt_one_minus_alphas_cumprod, t, x_0.shape)
    return sqrt_alphas_cumprod_t * x_0 + sqrt_one_minus_alphas_cumprod_t * noise, noise

BATCH_SIZE = 128
IMG_SIZE = 64

def load_transformed_dataset():
    data_transform = transforms.Compose([
        transforms.Resize((IMG_SIZE, IMG_SIZE)),
        transforms.ToTensor(),
        transforms.Lambda(lambda t: (t * 2) - 1)
    ])

    train = torchvision.datasets.MNIST(root=".", download=True, transform=data_transform)
    test = torchvision.datasets.MNIST(root=".", download=True, transform=data_transform)

    return torch.utils.data.ConcatDataset([train, test])

data = load_transformed_dataset()
dataloader = DataLoader(data, batch_size=BATCH_SIZE, shuffle=True, drop_last=True)

# Create a directory to save the images
output_dir = "forward_diffusion_imgs"
os.makedirs(output_dir, exist_ok=True)

# Number of steps and interval
step_interval = 10  # Interval between steps

# Simulate forward diffusion
image = next(iter(dataloader))[0]

# Loop over timesteps and display images
for idx in range(0, T, step_interval):  # Change T to ensure no out of bounds error
    t = torch.Tensor([idx]).type(torch.int64)

    try:
        img, _ = forward_diffusion_sample(image, t)  # Get the noisy image

        # Reverse normalization and convert to HWC format
        img_np = (img[0] + 1) / 2
        img_np = img_np.permute(1, 2, 0).cpu().numpy()

        # Save the image
        plt.figure(figsize=(4, 4))
        plt.imshow(img_np)
        plt.axis('off')
        plt.title(f"Image at Step {idx}")

        # Save the image with the step number in the filename
        plt.savefig(os.path.join(output_dir, f"image_step_{idx}.png"), bbox_inches='tight', pad_inches=0)
        plt.close()

    except IndexError as e:
        print(e)  # Print out the index error if it occurs

import shutil
from google.colab import files

# Compress the images into a ZIP file
shutil.make_archive("forward_diffusion_imgs", 'zip', output_dir)

# Download the ZIP file
files.download("forward_diffusion_imgs.zip")